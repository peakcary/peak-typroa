# 大模型的下一站：AI Agent！





2024-06-19 10:20·[人人都是产品经理](https://www.toutiao.com/c/user/token/MS4wLjABAAAAExPfV9TezI5CLpRTRUvWaWxgySiOsUugrwzBuZqUeXQ/?source=tuwen_detail)

> 现在各家基本上都有自己的大模型产品，现在的重点都是在找商业模式，以及扩展大模型的应用场景上。所以大家做APP、做Copilot也就不足为奇，都是为自己找出路的做法。但从作者的角度，Copilot只是传统互联网应用到大模型应用的过渡，AI Agent才是大模型的下一站！

![img](https://p3-sign.toutiaoimg.com/tos-cn-i-axegupay5k/d9502fac2b044789a8558025ac031a96~noop.image?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1719468662&x-signature=tBaJNsU2iVX9gJ%2BmW5xytClyktk%3D)

仔细想想**，自从Chat GPT发布之后，**大模型行业相关的玩家们其实一直在忙两件事：

1. **提升基座大模型的能力**：主力是国内外的大厂以及创业新势力，从最初的文、图、视频等单一模态到现在的综合多模态大模型，这些玩家利用Scaling Law，通过提升大模型的训练数据、训练算力和参数数量，以此来提升模型的性能，看这些市面上多如牛毛的大模型就知道这个方向成果颇丰。

不过虽然目前Scaling law还未失效，但其实已经遇到了递减的回报—也就是说，虽然模型性能会随资源投入量的增加而改善，但每增加一单位资源带来的性能提升会逐渐减少，何况还有数据、算力上限的掣肘，未来的这个赛道的激烈程度不言而喻。

**2. 探索大模型时代的Super APP**：其实从 GPT-4 的 Auto GPT、Baby GPT、GPT-Engineer 等开源 Agent 开始，大家对于大模型时代的AI Agent的探索就再也没有停歇！对于广大的小公司或者普通人而言，基座大模型如何发展他们参与感不强，大家的机会或者说是关注点则更倾向于如何将LLMs落地于应用。

李彦宏说：所有应用都值得被大模型重构一遍，但快两年了，为什么目前还没有看到令人兴奋的AI应用？我个人的思考是：大模型的能力不够强是一方面，但更大的问题是大家并没有考虑清楚什么是大模型时代的应用？遍历市场上所谓的大模型应用，其实90%都是**Copilot类**产品，本质还是互联网应用，只是在原始架构上简单累加或者罗列大模型的能力。

Copilot只是传统互联网应用到大模型应用的过渡，**AI Agent**才是大模型的下一站！



# 01.Agent的前世今生

## 1. 1986年到1997年：Software Agent

“**Agent**“这个术语在这个时期就已经出现了，包括Carl Eddie Hewitt和Michael Wooldridge在内的西方学术界的杰出计算机科学家们及人工智能研究者，对这一主题进行了深入的探讨，并展示了众多的系统示例及发表了大量研究论文，探讨了Software Agent在各种应用场景中的潜力。

可以说，过去三十年来，Agent的理念基本保持不变，但由于当时的AI和计算能力限制，该概念在90年代流行了一段时间后逐渐淡出视线。

这个时期的Agent的概念源自于日常生活中广泛存在的代理概念。这些日常代理，如旅行代理或房地产代理，代表他人行事且具有一定的自主性，例如房地产代理可在未经房主直接同意的情况下，为空置房产安排看房。这些普通代理展示了主动性和合作的能力。

根据当时的计算机专家定义，Agent的几个关键特征包括：

1. **自主性**（在无需人类干预的情况下独立运作，并控制其行为和内部状态）
2. **社交能力**（能通过某种通讯语言与其他代理或人类互动）
3. **反应能力**（能感知并及时响应外部环境的变化）
4. **主动性**（具备目标导向的行为，不仅响应环境，也会主动行动以达成目标）。



## 2. 2023年4月至今：AI Agent

GPT-4发布之后，以**AutoGPT、BabyAGI**等为代表的一批自主代理（Autonomous Agents）的开源内容再次引发了学术界和产业界对于Agent系统和概念的兴趣。其中，学术界的参与和热情更为明显，目前Github上大约95%的相关Demo均由全球的科研机构和高校提供。

![img](https://p26-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/da2de6e708451ab2fe69f9b8f517af63~noop.image?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1719468662&x-signature=dmXvuawXSYWTxiCWjhajr37vbGs%3D)

图片：斯坦福和谷歌论文《Generative Agents: Interactive Simulacra of Human Behavior》

现阶段人们对 AI Agent 的定义和 30 年前当时对 Software Agent 定义变化不大，期望仍然是：在有了目标后，独立决策并完成任务的。唯一区别就是传统的Software Agent更多是依赖预设的算法或者规则解决一些简单的、流程明确的任务，但是在大模型加入后，Agent对于目标任务的拆解、规划能力更强了。

大语言模型的加入为 Agents 设计带来了变革，基于大语言模型的 Agent 可以整合更多的工具，同时多模态的能力还可以让Agent感知复杂和未知的环境，在决策策略上也更有优势，甚至可以利用一些手段让 Agent 具备持续学习能力，提高 Agent 处理任务的多样性。

简单来说，我们希望理想的AI Agent是一个强大的通用问题解决方案助手。



# 02.理想的AI Agent应该有哪些组件？

如果把大模型比作大脑前叶，负责计算，那么 Agent 也许更像整个大脑，有记忆，规划，行动，和使用工具的能力。所以对比大模型，Agent 更像一个完整的 App。Agent 时代的人机交互就像人与人的交互一样，更自然，更沉浸，更个人化。

比如：AutoGPT ，这类 Autonomous Agent 核心是利用模型 COT 能力让大模型通过审视自己上一次调用工具后输出结果，审视自己是否有改进的空间，再进行下一步规划和改进，以此来“激发”大模型的主动性。

![img](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/cdabb245e33151fe1140efd3f36d7c5b~noop.image?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1719468662&x-signature=0y2U7Plv7PL1iK5T8QLcKq6zxDA%3D)

参考Open AI研究员翁丽莲、机器学习专家吴恩达以及多篇关于Autonomous agents 的文章，这里我给出我理解的理想的AI Agent构成。

**规划（Planning）：**

- **任务拆解**：Agent能将大任务分解为更小的、可管理的子目标，从而有效地处理复杂任务。对于每一个目标，评估使用不同行为方案的可行性，选择其中期望效果最好的一个。
- **反思与改进**：Agent可以接受来自人类或者环境的反馈，并反思历史的行为，从错误中吸取教训，并将错误内容加入长期记忆形成人类的教训，为未来的步骤进行改进，更新其对世界的认知，从而提高最终结果的质量。

**行动（Action）：**

负责将Agent的决策转化为特定的输出。

- **环境探索和交互**：Agent能够通过与环境交互获取新知识，并通过总结最近的经验来增强自己。通过这种方式可以生成越来越适应环境且符合常识的新行为。
- **记忆检索：**Agent根据存储在记忆模块中的经验做决定，在采取行动时，相关的记忆片段被检索作为 LLM 的条件输入，以确保先前的错误不会再犯。
- **工具使用：**可以通过文档和数据集教会 Agent 如何调用外部工具的 API，来补足 LLM 自身的弱项，甚至可以通过工具使用完成和硬件的交互。

**记忆（Memory）：**

信息可以用各种格式存储在记忆中，来模仿人类大脑那样从过往的经验中学习正确的工作模式。

- **短期记忆**：这一轮决策所需要用到的所有信息。其中包括上下文内容，目前Agent的记忆都是短期的。
- **长期记忆**：这为Agent提供了在较长时间内保留和回忆（无限）信息的能力，目前是通过利用外部向量存储和快速检索来实现的，未来可以建设一个记忆系统，能记忆各种图、文、向量数据信息，包括用户**用户偏好和工作习惯，**以此能做出更智能的决策。



# 03. 为什么说大模型下一站是：AI Agent

## 1. AI Agent 将成为人类新的系统2

在《思考，快与慢》一书中，人的认知过程被划分为两大类，即系统 1 和系统 2。前者是快速且依赖直觉的思考模式，尽管灵活迅速，却容易犯错。后者则是缓慢而逻辑的思考方式，虽然速度较慢，但结果往往更为可靠和准确。

大型语言模型（LLMs）非常适合执行类似系统 1 的任务，它能迅速处理和回应大量信息，类似于人们在听到信息后能立刻理解和回答。然而，LLM 有时会产生幻觉效应，即造出不存在的事实，这种现象与人类的直觉思考中的偏误和本能响应有着相似之处。

而AI Agent的一项重要长期目标是让LLM能够担任类似系统 2 的角色，在深度思考和分析基础上做出更为复杂和可信的决策。CoT的研究就是这方面的一个杰出例子，它通过提示来让大模型模拟人类复杂的推理过程，以此激发出LLM更高级的智能，帮助和辅助人类进行思考，甚至是帮助人类完成行动。



## 2. AI Agent 将低成本为每个人实现软件定制

Andrej Karpathy 曾提出”Software 2.0″的概念，强调通过大数据和强大的计算力，可以有效处理此前需要大量人工和高成本才能解决的复杂问题，AI Agent正是将这一观念具体化的例子。

当前，市面上的主流软件多为用户群体大、标准化高的需求所设计，只有当需求量足够大时，企业才会投入资源开发。然而，许多小众、特异化的需求常常得不到满足。随着AI Agent的成熟，软件开发将实现成本的大幅降低。使软件能够灵活应对人类更加多样化的需求，开启类似于“3D打印”的软件生产新时代，为用户提供更加个性化的产品选择。



# 04.写在最后

短期，我们认为文章预想的Autonomous Agent 落地有些困难，因为上面也讲了是理想状态下的AI Agent，这就要求Agent有相当强大的自驱和自动化规划能力，但是在当前的大模型能力加持下，要想实现这样的效果，几乎不太可能。如果是短期的 AI Agent 产品，我们需要给产品的用户提供干预空间，让Agent辅助用户完成任务，保证至少有60%的事情是Agent完成的。

不过长期来看，我们还是对 AI Agent 相当有信心，OpenAI 等大模型公司会在模型推理能力上持续进化，奔着AGI在狂奔，所以谁知道GPT5 会带给我们什么惊喜呢！

本文由 @小布Bruce 原创发布于人人都是产品经理。未经作者许可，禁止转载

题图来自 Unsplash，基于CC0协议

该文观点仅代表作者本人，人人都是产品经理平台仅提供信息存储空间服务



[link](https://www.toutiao.com/article/7382033510875398665/?app=news_article&timestamp=1718772652&use_new_style=1&req_id=202406191250525812B590F81142039C1E&group_id=7382033510875398665&share_token=18E75C89-8848-4E0F-99BD-0176383C21E3&tt_from=weixin&utm_source=weixin&utm_medium=toutiao_ios&utm_campaign=client_share&wxshare_count=1&source=m_redirect)
